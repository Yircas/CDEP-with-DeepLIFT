{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/irenetrampoline/compas-python/blob/master/COMPAS_Python.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.stats import pearsonr\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from score_funcs import cdep\n",
    "from copy import deepcopy\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from model import  Net\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch\n",
    "import torch\n",
    "from model import Net\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "\n",
    "torch.backends.cudnn.deterministic = True #this makes results reproducible. \n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../compas-analysis/compas-scores-two-years.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../compas-analysis/compas-scores-two-years.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum rows: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\u001b[38;5;28mlen\u001b[39m(raw_data))\n",
      "File \u001b[0;32m~/anaconda3/envs/CDEP/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CDEP/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/CDEP/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CDEP/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/CDEP/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../compas-analysis/compas-scores-two-years.csv'"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('compas-analysis/compas-scores-two-years.csv') # raw_data = pd.read_csv('../../compas-analysis/compas-scores-two-years.csv')\n",
    "print('Num rows: %d' %len(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows filtered: 6172\n"
     ]
    }
   ],
   "source": [
    "df = raw_data[((raw_data['days_b_screening_arrest'] <=30) & \n",
    "      (raw_data['days_b_screening_arrest'] >= -30) &\n",
    "      (raw_data['is_recid'] != -1) &\n",
    "      (raw_data['c_charge_degree'] != 'O') & \n",
    "      (raw_data['score_text'] != 'N/A')\n",
    "     )].copy()\n",
    "\n",
    "print('Num rows filtered: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crimes = df.c_charge_desc.value_counts().to_frame()\n",
    "crimes['description'] = crimes.index\n",
    "crimes['classified']= False\n",
    "words = ['Battery', 'Assault','Violence', 'no charge', 'Possession', 'Poss', 'Pos', 'Theft', 'Driving', 'DUI', 'Burglary', 'Drivers','Cocaine', 'License','Abuse']\n",
    "for word in words:\n",
    "    crimes['classified'] = crimes['description'].str.contains(word) | crimes['classified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   c_charge_desc  \\\n",
      "Battery                                     1087   \n",
      "arrest case no charge                        784   \n",
      "Possession of Cocaine                        419   \n",
      "Grand Theft in the 3rd Degree                384   \n",
      "Driving While License Revoked                189   \n",
      "Driving Under The Influence                  126   \n",
      "Felony Driving While Lic Suspd                93   \n",
      "Pos Cannabis W/Intent Sel/Del                 93   \n",
      "Felony Battery (Dom Strang)                   92   \n",
      "Grand Theft (Motor Vehicle)                   92   \n",
      "Possess Cannabis/20 Grams Or Less             79   \n",
      "Burglary Unoccupied Dwelling                  77   \n",
      "DUI Property Damage/Injury                    70   \n",
      "Burglary Conveyance Unoccup                   68   \n",
      "Poss3,4 Methylenedioxymethcath                68   \n",
      "Possession of Cannabis                        68   \n",
      "Felony Petit Theft                            60   \n",
      "Aggrav Battery w/Deadly Weapon                57   \n",
      "DUI Level 0.15 Or Minor In Veh                54   \n",
      "Aggravated Assault W/Dead Weap                54   \n",
      "Aggravated Battery / Pregnant                 48   \n",
      "Uttering a Forged Instrument                  47   \n",
      "Viol Injunct Domestic Violence                47   \n",
      "Resist Officer w/Violence                     46   \n",
      "Battery on Law Enforc Officer                 46   \n",
      "Tampering With Physical Evidence              46   \n",
      "Susp Drivers Lic 1st Offense                  45   \n",
      "Possession Of Alprazolam                      44   \n",
      "Driving License Suspended                     44   \n",
      "Felony Battery w/Prior Convict                38   \n",
      "Assault                                       38   \n",
      "Poss Pyrrolidinovalerophenone                 37   \n",
      "Resist/Obstruct W/O Violence                  36   \n",
      "Burglary Structure Unoccup                    35   \n",
      "Aggravated Assault W/dead Weap                34   \n",
      "Carrying Concealed Firearm                    34   \n",
      "Agg Battery Grt/Bod/Harm                      31   \n",
      "Possession Burglary Tools                     29   \n",
      "Petit Theft                                   29   \n",
      "Operating W/O Valid License                   28   \n",
      "Disorderly Conduct                            27   \n",
      "Crim Use of Personal ID Info                  26   \n",
      "Possession Of Methamphetamine                 26   \n",
      "Burglary Dwelling Occupied                    26   \n",
      "False Imprisonment                            24   \n",
      "Deliver Cocaine                               23   \n",
      "Possession of Oxycodone                       22   \n",
      "Aggravated Assault w/Firearm                  22   \n",
      "Possession Of Heroin                          21   \n",
      "Tamper With Witness/Victim/CI                 21   \n",
      "Poss Contr Subst W/o Prescript                21   \n",
      "\n",
      "                                                         description  \\\n",
      "Battery                                                      Battery   \n",
      "arrest case no charge                          arrest case no charge   \n",
      "Possession of Cocaine                          Possession of Cocaine   \n",
      "Grand Theft in the 3rd Degree          Grand Theft in the 3rd Degree   \n",
      "Driving While License Revoked          Driving While License Revoked   \n",
      "Driving Under The Influence              Driving Under The Influence   \n",
      "Felony Driving While Lic Suspd        Felony Driving While Lic Suspd   \n",
      "Pos Cannabis W/Intent Sel/Del          Pos Cannabis W/Intent Sel/Del   \n",
      "Felony Battery (Dom Strang)              Felony Battery (Dom Strang)   \n",
      "Grand Theft (Motor Vehicle)              Grand Theft (Motor Vehicle)   \n",
      "Possess Cannabis/20 Grams Or Less  Possess Cannabis/20 Grams Or Less   \n",
      "Burglary Unoccupied Dwelling            Burglary Unoccupied Dwelling   \n",
      "DUI Property Damage/Injury                DUI Property Damage/Injury   \n",
      "Burglary Conveyance Unoccup              Burglary Conveyance Unoccup   \n",
      "Poss3,4 Methylenedioxymethcath        Poss3,4 Methylenedioxymethcath   \n",
      "Possession of Cannabis                        Possession of Cannabis   \n",
      "Felony Petit Theft                                Felony Petit Theft   \n",
      "Aggrav Battery w/Deadly Weapon        Aggrav Battery w/Deadly Weapon   \n",
      "DUI Level 0.15 Or Minor In Veh        DUI Level 0.15 Or Minor In Veh   \n",
      "Aggravated Assault W/Dead Weap        Aggravated Assault W/Dead Weap   \n",
      "Aggravated Battery / Pregnant          Aggravated Battery / Pregnant   \n",
      "Uttering a Forged Instrument            Uttering a Forged Instrument   \n",
      "Viol Injunct Domestic Violence        Viol Injunct Domestic Violence   \n",
      "Resist Officer w/Violence                  Resist Officer w/Violence   \n",
      "Battery on Law Enforc Officer          Battery on Law Enforc Officer   \n",
      "Tampering With Physical Evidence    Tampering With Physical Evidence   \n",
      "Susp Drivers Lic 1st Offense            Susp Drivers Lic 1st Offense   \n",
      "Possession Of Alprazolam                    Possession Of Alprazolam   \n",
      "Driving License Suspended                  Driving License Suspended   \n",
      "Felony Battery w/Prior Convict        Felony Battery w/Prior Convict   \n",
      "Assault                                                      Assault   \n",
      "Poss Pyrrolidinovalerophenone          Poss Pyrrolidinovalerophenone   \n",
      "Resist/Obstruct W/O Violence            Resist/Obstruct W/O Violence   \n",
      "Burglary Structure Unoccup                Burglary Structure Unoccup   \n",
      "Aggravated Assault W/dead Weap        Aggravated Assault W/dead Weap   \n",
      "Carrying Concealed Firearm                Carrying Concealed Firearm   \n",
      "Agg Battery Grt/Bod/Harm                    Agg Battery Grt/Bod/Harm   \n",
      "Possession Burglary Tools                  Possession Burglary Tools   \n",
      "Petit Theft                                              Petit Theft   \n",
      "Operating W/O Valid License              Operating W/O Valid License   \n",
      "Disorderly Conduct                                Disorderly Conduct   \n",
      "Crim Use of Personal ID Info            Crim Use of Personal ID Info   \n",
      "Possession Of Methamphetamine          Possession Of Methamphetamine   \n",
      "Burglary Dwelling Occupied                Burglary Dwelling Occupied   \n",
      "False Imprisonment                                False Imprisonment   \n",
      "Deliver Cocaine                                      Deliver Cocaine   \n",
      "Possession of Oxycodone                      Possession of Oxycodone   \n",
      "Aggravated Assault w/Firearm            Aggravated Assault w/Firearm   \n",
      "Possession Of Heroin                            Possession Of Heroin   \n",
      "Tamper With Witness/Victim/CI          Tamper With Witness/Victim/CI   \n",
      "Poss Contr Subst W/o Prescript        Poss Contr Subst W/o Prescript   \n",
      "\n",
      "                                   classified  \n",
      "Battery                                  True  \n",
      "arrest case no charge                    True  \n",
      "Possession of Cocaine                    True  \n",
      "Grand Theft in the 3rd Degree            True  \n",
      "Driving While License Revoked            True  \n",
      "Driving Under The Influence              True  \n",
      "Felony Driving While Lic Suspd           True  \n",
      "Pos Cannabis W/Intent Sel/Del            True  \n",
      "Felony Battery (Dom Strang)              True  \n",
      "Grand Theft (Motor Vehicle)              True  \n",
      "Possess Cannabis/20 Grams Or Less        True  \n",
      "Burglary Unoccupied Dwelling             True  \n",
      "DUI Property Damage/Injury               True  \n",
      "Burglary Conveyance Unoccup              True  \n",
      "Poss3,4 Methylenedioxymethcath           True  \n",
      "Possession of Cannabis                   True  \n",
      "Felony Petit Theft                       True  \n",
      "Aggrav Battery w/Deadly Weapon           True  \n",
      "DUI Level 0.15 Or Minor In Veh           True  \n",
      "Aggravated Assault W/Dead Weap           True  \n",
      "Aggravated Battery / Pregnant            True  \n",
      "Uttering a Forged Instrument            False  \n",
      "Viol Injunct Domestic Violence           True  \n",
      "Resist Officer w/Violence                True  \n",
      "Battery on Law Enforc Officer            True  \n",
      "Tampering With Physical Evidence        False  \n",
      "Susp Drivers Lic 1st Offense             True  \n",
      "Possession Of Alprazolam                 True  \n",
      "Driving License Suspended                True  \n",
      "Felony Battery w/Prior Convict           True  \n",
      "Assault                                  True  \n",
      "Poss Pyrrolidinovalerophenone            True  \n",
      "Resist/Obstruct W/O Violence             True  \n",
      "Burglary Structure Unoccup               True  \n",
      "Aggravated Assault W/dead Weap           True  \n",
      "Carrying Concealed Firearm              False  \n",
      "Agg Battery Grt/Bod/Harm                 True  \n",
      "Possession Burglary Tools                True  \n",
      "Petit Theft                              True  \n",
      "Operating W/O Valid License              True  \n",
      "Disorderly Conduct                      False  \n",
      "Crim Use of Personal ID Info            False  \n",
      "Possession Of Methamphetamine            True  \n",
      "Burglary Dwelling Occupied               True  \n",
      "False Imprisonment                      False  \n",
      "Deliver Cocaine                          True  \n",
      "Possession of Oxycodone                  True  \n",
      "Aggravated Assault w/Firearm             True  \n",
      "Possession Of Heroin                     True  \n",
      "Tamper With Witness/Victim/CI           False  \n",
      "Poss Contr Subst W/o Prescript           True  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(crimes[crimes.c_charge_desc >20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c_charge_desc'] = df['c_charge_desc'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_book = {'possession' : ['Possession'  'Poss', 'Cocaine','Cannabis'],\n",
    "'violence' : ['Battery','Assault', 'Violence', 'Abuse'],\n",
    "'theft' : ['Theft', 'Burglary', ],\n",
    "'driving' : ['Drivers', 'Driving', 'License', 'Drivers', 'DUI','Veh'],\n",
    "'nocharge' : ['no charge'],}\n",
    "df['classified'] = 0\n",
    "\n",
    "for key in black_book.keys():\n",
    "    df[key] = 0\n",
    "    for word in black_book[key]:\n",
    "        df[key]= df[key] +   df['c_charge_desc'].str.contains(word).astype(bool).astype(int)\n",
    "        df['classified'] =df['classified'] |  df['c_charge_desc'].str.contains(word).astype(bool).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.get_dummies(df['c_charge_degree'],prefix='crimefactor',drop_first=True)\n",
    "df_age = pd.get_dummies(df['age_cat'],prefix='age')\n",
    "df_race = pd.get_dummies(df['race'],prefix='race')\n",
    "df_gender = pd.get_dummies(df['sex'],prefix='sex',drop_first=True)\n",
    "df_score = pd.get_dummies(df['score_text'] != 'Low',prefix='score_factor',drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.concat([df_race, df_crime, df_age,df_gender,\n",
    "                   df['priors_count'],\n",
    "                   df['theft'],\n",
    "                   df['driving'],\n",
    "                   df['possession'],\n",
    "                   df['violence'],\n",
    "                   df['nocharge']\n",
    "                  ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  torch.tensor(df_lr.values).float()\n",
    "y= torch.tensor(df['two_year_recid'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x,y)\n",
    "num_total = len(dataset)\n",
    "num_train = int(0.8 * num_total)\n",
    "num_val = int(0.1 * num_total)\n",
    "num_test = num_total - num_train - num_val\n",
    "torch.manual_seed(0);\n",
    "train_dataset, test_dataset ,val_dataset= torch.utils.data.random_split(dataset, [num_train, num_test, num_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'train' : train_dataset, 'test':test_dataset, 'val': val_dataset}\n",
    "dataset_sizes = {'train' : len(train_dataset), 'test':len(test_dataset), 'val': len(val_dataset)}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=256, \n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'test','val']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'seed':[], 'regularizer_rate':[],\n",
    "                    \"test_acc\":[], \n",
    "                    \"test_loss\":[],\n",
    "                   'black_wc': [],\n",
    "                   'black_wf':[],\n",
    "                   'white_wc':[],\n",
    "                   'white_wf':[],\n",
    "                   \n",
    "                   'insensitivity':[]}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "patience = 10\n",
    "num_epochs =1000\n",
    "\n",
    "weights = np.asarray([len(datasets['train'])/(datasets['train'].dataset[datasets['train'].indices][1]==0).sum().item(), len(train_dataset)/datasets['train'].dataset[datasets['train'].indices][1].sum().item()])\n",
    "weights /= weights.sum()\n",
    "weights = torch.tensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = weights.double().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_race = np.zeros((17))\n",
    "blob_race[:] =1\n",
    "blob_norace = np.zeros((17))\n",
    "blob_norace[6:] = 1\n",
    "def train( model, device, train_loader, optimizer, epoch, regularizer_rate):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss =criterion(output, target)\n",
    "        add_loss = torch.zeros(1,).cuda()\n",
    "        if regularizer_rate != 0:\n",
    "            add_loss += cdep(model, data, blob_norace) \n",
    "        (loss+regularizer_rate*add_loss).backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            acc = 100.*pred.eq(target.view_as(pred)).sum().item()/len(target)\n",
    "\n",
    "def test(model, device, test_loader, epoch, verbose = False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data[:,:6] =0\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "#     s.losses_test.append(test_loss)\n",
    "#     s.accs_test.append(100. * correct / len(test_loader.dataset))\n",
    "    return test_loss,test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'seed':[], 'regularizer_rate':[],\n",
    "                    \"test_acc\":[], \n",
    "                    \"test_loss\":[],\n",
    "                   'black_wc': [],\n",
    "                   'black_wf':[],\n",
    "                   'white_wc':[],\n",
    "                   'white_wf':[],\n",
    "                    'weights' :[],\n",
    "                   \n",
    "                   'insensitivity':[]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1531a27beb348229fe2433c6958be38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6211, Accuracy: 409/617 (66%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa0c03f5cfc4456a90986974e7b9b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6031, Accuracy: 424/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922a3538ba614013ae8fb22a04f981f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6044, Accuracy: 416/617 (67%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3778785b2f4991bf8d8a0257c66d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5908, Accuracy: 426/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc16bd52cf8d4279b4f3d860f8b76604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6015, Accuracy: 425/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc52269d6c40485d9826975b57760b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5987, Accuracy: 421/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce0971a89a849ff95b0d034eda5d310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6113, Accuracy: 421/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8932b997144cd5b18d1fe951951e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5979, Accuracy: 425/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e37f9829a8f4618ab4f8220f486146d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5973, Accuracy: 422/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1e4b7b87f3404a8d165d7a474b3247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5945, Accuracy: 426/617 (69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regularizer_rates = [0,1]\n",
    "val_x, val_y = val_dataset.dataset[val_dataset.indices] #needed for calculating race specific accs\n",
    "for seed in range(5):\n",
    "    for regularizer_rate  in regularizer_rates:\n",
    "        torch.manual_seed(seed) #weight init is varied\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        best_model_weights = None\n",
    "        best_test_loss = 100000\n",
    "\n",
    "        cur_patience = 0\n",
    "        net = Net().cuda()\n",
    "        optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum =0.9)\n",
    "        for epoch in tqdm_notebook(range(num_epochs)):\n",
    "\n",
    "            train( net, device, dataloaders['train'], optimizer, epoch, regularizer_rate)\n",
    "            test_loss = test(net, device, dataloaders['test'], epoch)\n",
    "            if test_loss[0] < best_test_loss:\n",
    "\n",
    "                cur_patience = 0\n",
    "                best_test_loss = test_loss[0]\n",
    "                best_model_weights = deepcopy(net.state_dict())\n",
    "            else:\n",
    "                cur_patience +=1\n",
    "                if cur_patience > patience:\n",
    "                    break\n",
    "        net.load_state_dict(best_model_weights)\n",
    "        test_loss, test_acc = test(net, device, dataloaders['val'], epoch+1, verbose = True)\n",
    "\n",
    "\n",
    "        val_out = net(val_x.cuda())\n",
    "        def calc_fairness(race_int):\n",
    "            black_mask = (val_x[:, race_int] ==1).bool() #\n",
    "            val_out_black = val_out.argmax(dim=1).cpu().masked_select(black_mask)\n",
    "            val_y_black = val_y.cpu().masked_select(black_mask)\n",
    "            fp = ((val_out_black ==1)*(val_y_black ==0)).sum().item()\n",
    "            tp = ((val_out_black ==1)*(val_y_black ==1)).sum().item()\n",
    "            fn = ((val_out_black ==0)*(val_y_black ==1)).sum().item()\n",
    "            tn = ((val_out_black ==0)*(val_y_black ==0)).sum().item()\n",
    "            wrongly_incarcerated = fp/(tn+fp)\n",
    "            wrongly_let_go = fn/(tp+fn)\n",
    "            return (wrongly_incarcerated, wrongly_let_go)\n",
    "\n",
    "        black_wc, black_wf = calc_fairness(0)\n",
    "        white_wc, white_wf = calc_fairness(2)\n",
    "#         diff_black, diff_white = test_change(net)\n",
    "        df1 = df1.append(pd.DataFrame({'seed': [seed], 'regularizer_rate':[regularizer_rate],\n",
    "                        \"test_acc\":[test_acc], \n",
    "                        \"test_loss\":[test_loss],\n",
    "                       'black_wc': [black_wc],\n",
    "                       'black_wf':[black_wf],\n",
    "                       'white_wc':[white_wc],\n",
    "                       'white_wf':[white_wf],\n",
    "                                       \n",
    "                       'weights':[best_model_weights],\n",
    "                        'insensitivity' :0 }))\n",
    "df1['equalized_odds_wc'] = df1['black_wc'] / df1['white_wc'] \n",
    "df1['equalized_odds_wf'] = df1['black_wf'] / df1['white_wf'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>black_wc</th>\n",
       "      <th>white_wc</th>\n",
       "      <th>equalized_odds_wc</th>\n",
       "      <th>equalized_odds_wf</th>\n",
       "      <th>black_wf</th>\n",
       "      <th>white_wf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>67.84</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>68.78</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_acc  black_wc  white_wc  equalized_odds_wc  \\\n",
       "regularizer_rate                                                    \n",
       "0.0                  67.84      0.47      0.22               2.17   \n",
       "1.0                  68.78      0.39      0.20               1.91   \n",
       "\n",
       "                  equalized_odds_wf  black_wf  white_wf  \n",
       "regularizer_rate                                         \n",
       "0.0                            0.54      0.24      0.44  \n",
       "1.0                            0.56      0.27      0.48  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['regularizer_rate']).mean()[['test_acc', 'black_wc', 'white_wc', 'equalized_odds_wc','equalized_odds_wf', 'black_wf', 'white_wf']].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with sensitive attribute hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_race = np.zeros((17))\n",
    "blob_race[:] =1\n",
    "blob_norace = np.zeros((17))\n",
    "blob_norace[6:] = 1\n",
    "def train( model, device, train_loader, optimizer, epoch, regularizer_rate):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data[:,:6] = 0\n",
    "\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss =criterion(output, target)\n",
    "        add_loss = torch.zeros(1,).cuda()\n",
    "\n",
    "        (loss).backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            acc = 100.*pred.eq(target.view_as(pred)).sum().item()/len(target)\n",
    "\n",
    "def test(model, device, test_loader, epoch, verbose = False,):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data[:,:6] =0\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "#     s.losses_test.append(test_loss)\n",
    "#     s.accs_test.append(100. * correct / len(test_loader.dataset))\n",
    "    return test_loss,test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847a914fd3ef498097f387aaa5471270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6038, Accuracy: 424/617 (69%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/.local/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f806b9883ebb4b0c863b554f4ad51ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6033, Accuracy: 419/617 (68%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0411dfa022545e3aaa4876937963e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5964, Accuracy: 423/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6dc6556a9b4e5cbb0e40f00c257e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6046, Accuracy: 424/617 (69%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678b7c4305db4c37913701d1faed5582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6050, Accuracy: 423/617 (69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regularizer_rates = [-1]\n",
    "val_x, val_y = val_dataset.dataset[val_dataset.indices] #needed for calculating race specific accs\n",
    "for seed in range(5):\n",
    "    for regularizer_rate  in regularizer_rates:\n",
    "        torch.manual_seed(seed) #weight init is varied\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        best_model_weights = None\n",
    "        best_test_loss = 100000\n",
    "\n",
    "        cur_patience = 0\n",
    "        net = Net().cuda()\n",
    "        optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum =0.9)\n",
    "        for epoch in tqdm_notebook(range(num_epochs)):\n",
    "\n",
    "            train( net, device, dataloaders['train'], optimizer, epoch, regularizer_rate)\n",
    "            test_loss = test(net, device, dataloaders['test'], epoch)\n",
    "            if test_loss[0] < best_test_loss:\n",
    "\n",
    "                cur_patience = 0\n",
    "                best_test_loss = test_loss[0]\n",
    "                best_model_weights = deepcopy(net.state_dict())\n",
    "            else:\n",
    "                cur_patience +=1\n",
    "                if cur_patience > patience:\n",
    "                    break\n",
    "        net.load_state_dict(best_model_weights)\n",
    "        test_loss, test_acc = test(net, device, dataloaders['val'], epoch+1, verbose = True)\n",
    "\n",
    "\n",
    "        \n",
    "        def calc_fairness(race_int):\n",
    "            black_mask = (val_x[:, race_int] ==1).bool() #\n",
    "            val_x_copy = val_x.clone().detach().cuda()\n",
    "            val_x_copy[:,:6] =0\n",
    "            val_out = net(val_x_copy.cuda())\n",
    "            val_out_black = val_out.argmax(dim=1).cpu().masked_select(black_mask)\n",
    "            val_y_black = val_y.cpu().masked_select(black_mask)\n",
    "            fp = ((val_out_black ==1)*(val_y_black ==0)).sum().item()\n",
    "            tp = ((val_out_black ==1)*(val_y_black ==1)).sum().item()\n",
    "            fn = ((val_out_black ==0)*(val_y_black ==1)).sum().item()\n",
    "            tn = ((val_out_black ==0)*(val_y_black ==0)).sum().item()\n",
    "            wrongly_incarcerated = fp/(tn+fp)\n",
    "            wrongly_let_go = fn/(tp+fn)\n",
    "            return (wrongly_incarcerated, wrongly_let_go)\n",
    "\n",
    "        black_wc, black_wf = calc_fairness(0)\n",
    "        white_wc, white_wf = calc_fairness(2)\n",
    "#         diff_black, diff_white = test_change(net)\n",
    "        df1 = df1.append(pd.DataFrame({'seed': [seed], 'regularizer_rate':[regularizer_rate],\n",
    "                        \"test_acc\":[test_acc], \n",
    "                        \"test_loss\":[test_loss],\n",
    "                       'black_wc': [black_wc],\n",
    "                       'black_wf':[black_wf],\n",
    "                       'white_wc':[white_wc],\n",
    "                       'white_wf':[white_wf],\n",
    "                                       \n",
    "                       'weights':[best_model_weights],\n",
    "                        'insensitivity' :0 }))\n",
    "df1['equalized_odds_wc'] = df1['black_wc'] / df1['white_wc'] \n",
    "df1['equalized_odds_wf'] = df1['black_wf'] / df1['white_wf'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regularizer rate -1 refers to the network trained blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>black_wc</th>\n",
       "      <th>white_wc</th>\n",
       "      <th>equalized_odds_wc</th>\n",
       "      <th>equalized_odds_wf</th>\n",
       "      <th>black_wf</th>\n",
       "      <th>white_wf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>68.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>67.84</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>68.78</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_acc  black_wc  white_wc  equalized_odds_wc  \\\n",
       "regularizer_rate                                                    \n",
       "-1.0                 68.49      0.44      0.23               1.96   \n",
       " 0.0                 67.84      0.47      0.22               2.17   \n",
       " 1.0                 68.78      0.39      0.20               1.91   \n",
       "\n",
       "                  equalized_odds_wf  black_wf  white_wf  \n",
       "regularizer_rate                                         \n",
       "-1.0                           0.58      0.24      0.42  \n",
       " 0.0                           0.54      0.24      0.44  \n",
       " 1.0                           0.56      0.27      0.48  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['regularizer_rate']).mean()[['test_acc', 'black_wc', 'white_wc', 'equalized_odds_wc','equalized_odds_wf', 'black_wf', 'white_wf']].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>black_wc</th>\n",
       "      <th>white_wc</th>\n",
       "      <th>equalized_odds_wc</th>\n",
       "      <th>equalized_odds_wf</th>\n",
       "      <th>black_wf</th>\n",
       "      <th>white_wf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularizer_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_acc  black_wc  white_wc  equalized_odds_wc  \\\n",
       "regularizer_rate                                                    \n",
       "-1.0                  0.34      0.02      0.01               0.06   \n",
       " 0.0                  1.02      0.03      0.03               0.23   \n",
       " 1.0                  0.34      0.04      0.01               0.16   \n",
       "\n",
       "                  equalized_odds_wf  black_wf  white_wf  \n",
       "regularizer_rate                                         \n",
       "-1.0                           0.02      0.01      0.01  \n",
       " 0.0                           0.03      0.02      0.04  \n",
       " 1.0                           0.03      0.02      0.02  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['regularizer_rate']).std()[['test_acc', 'black_wc', 'white_wc', 'equalized_odds_wc','equalized_odds_wf', 'black_wf', 'white_wf']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CDEP",
   "language": "python",
   "name": "cdep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
